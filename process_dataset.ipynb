{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "from modules.module import load_config_file, pair, get_elicitation_time_by_subject, load_frames, load_gaze_and_diameter\n",
    "from modules.preprocessing import preprocess_gaze_pupil_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0a': {'all': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, '0b': {'all': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, '1a': {'0:35': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, '1b': {'1:26': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, '2a': {'0:19': [1, 2, 3, 5, 7, 8, 10, 11, 12, 14, 16, 17], '1:20': [4, 6, 9, 13, 15, 18, 19, 20]}, '2b': {'0:06': [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19], '0:45': [4, 16], '1:30': [7, 20]}, '3a': {'1:37': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20], '2:00': [11, 17, 18]}, '3b': {'0:55': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, '4a': {'0:32': [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20], '1:35': [2, 14]}, '4b': {'0:31': [9], '0:56': [1, 2, 3, 4, 5, 6, 8, 11, 12, 13, 15, 17, 19, 20], '1:23': [7, 10, 14, 16, 18]}, '5a': {'0:38': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, '5b': {'0:35': [1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20]}, '6a': {'0:10': [4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20], '0:28': [1, 2, 6], '0:42': [7]}, '6b': {'0:10': [1, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], '0:40': [8, 15], '0:47': [3, 9]}}\n",
      "{'raw_data_dir': 'eyes_emo_multi_representation_single_sub', 'destination_dir': 'processed_dataset', 'periocular_sample_rate': 10, 'scene_sample_rate': 10, 'periocular_channels': 1, 'scene_channels': 3, 'periocular_resolution': 224, 'scene_resolution': 224, 'gaze_pupil_sample_rate': 120, 'window_time': 1.0, 'overlap': 0.0}\n",
      "['P01']\n"
     ]
    }
   ],
   "source": [
    "user_label = load_config_file(\"user_label.json\")\n",
    "\n",
    "config = load_config_file(\"modules/dataset_config.json\")\n",
    "\n",
    "frame_size = pair(config['periocular_resolution']) if config['periocular_resolution'] else sys.exit(\"Periocular resolution is not specified in the config file.\")\n",
    "\n",
    "subject_dirs = sorted([\n",
    "    d for d in os.listdir(config['raw_data_dir'])\n",
    "    if os.path.isdir(os.path.join(config['raw_data_dir'], d))\n",
    "])\n",
    "\n",
    "print(subject_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames_array shape: (43, 10, 224, 224, 1)\n",
      "frames_array shape: (43, 10, 224, 224, 1)\n",
      "frames_array shape: (31, 10, 224, 224, 1)\n",
      "frames_array shape: (31, 10, 224, 224, 1)\n",
      "frames_array shape: (5, 10, 224, 224, 1)\n",
      "frames_array shape: (5, 10, 224, 224, 1)\n",
      "frames_array shape: (10, 10, 224, 224, 1)\n",
      "frames_array shape: (10, 10, 224, 224, 1)\n",
      "frames_array shape: (133, 10, 224, 224, 1)\n",
      "frames_array shape: (133, 10, 224, 224, 1)\n",
      "frames_array shape: (108, 10, 224, 224, 1)\n",
      "frames_array shape: (108, 10, 224, 224, 1)\n",
      "frames_array shape: (46, 10, 224, 224, 1)\n",
      "frames_array shape: (47, 10, 224, 224, 1)\n",
      "frames_array shape: (53, 10, 224, 224, 1)\n",
      "frames_array shape: (53, 10, 224, 224, 1)\n",
      "frames_array shape: (85, 10, 224, 224, 1)\n",
      "frames_array shape: (85, 10, 224, 224, 1)\n",
      "frames_array shape: (64, 10, 224, 224, 1)\n",
      "frames_array shape: (64, 10, 224, 224, 1)\n",
      "frames_array shape: (112, 10, 224, 224, 1)\n",
      "frames_array shape: (113, 10, 224, 224, 1)\n",
      "frames_array shape: (13, 10, 224, 224, 1)\n",
      "frames_array shape: (13, 10, 224, 224, 1)\n",
      "frames_array shape: (35, 10, 224, 224, 1)\n",
      "frames_array shape: (35, 10, 224, 224, 1)\n",
      "frames_array shape: (132, 10, 224, 224, 1)\n",
      "frames_array shape: (133, 10, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "min_index_counter = 0\n",
    "max_index_counter = 0\n",
    "session_amount_counter = 0\n",
    "\n",
    "all_subjects_index_info = {}\n",
    "\n",
    "destination_dir = os.path.join(config['destination_dir'], f\"window_{config['window_time']}_fps_{config['periocular_sample_rate']}_fsize_{config['periocular_resolution']}_fchannel_{config['periocular_channels']}_gaze_pupil_rate_{config['gaze_pupil_sample_rate']}_overlap_{config['overlap']}\")\n",
    "\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "for subject in subject_dirs:\n",
    "\n",
    "    # Get the subject number\n",
    "    subject_number = int(subject.replace('P', ''))\n",
    "\n",
    "\n",
    "    session_dirs = sorted([\n",
    "        d for d in os.listdir(os.path.join(config['raw_data_dir'], subject))\n",
    "        if os.path.isdir(os.path.join(config['raw_data_dir'], subject, d))\n",
    "    ])\n",
    "\n",
    "    subject_h5_file = os.path.join(destination_dir, f\"{subject}.h5\")\n",
    "\n",
    "    for session in session_dirs:\n",
    "        # Get the elicitation time of the session\n",
    "        elicitation_time = get_elicitation_time_by_subject(user_label, session, subject_number)\n",
    "\n",
    "        match = re.match(r'(\\d+)([a-z])', session.lower())\n",
    "        if match:\n",
    "            session_number = int(match.group(1))\n",
    "            session_type = match.group(2)\n",
    "        else:\n",
    "            sys.exit(\"Error: The provided string does not match the required format (number followed by a lowercase letter).\")\n",
    "\n",
    "        if elicitation_time == \"none\":\n",
    "            print(f\"Subject {subject} claimed no emotion elicitation for session {session}\")\n",
    "        else:\n",
    "            # Calculate the elicitation time in seconds\n",
    "            if elicitation_time == \"all\":\n",
    "                elicitation_time_in_seconds = 0\n",
    "            else:\n",
    "                minutes, seconds = elicitation_time.split(':')\n",
    "                elicitation_time_in_seconds = int(minutes) * 60 + int(seconds)\n",
    "\n",
    "            # Process the periocular recordings\n",
    "            right_recording_path = os.path.join(config['raw_data_dir'], subject, session, 'periocular', 'eye0.mp4')\n",
    "            left_recording_path = os.path.join(config['raw_data_dir'], subject, session, 'periocular', 'eye1.mp4')\n",
    "\n",
    "            inversed_right_frames, right_duration = load_frames(right_recording_path, config['window_time'], elicitation_time_in_seconds, 120, config['periocular_sample_rate'], preprocess='none', resize=pair(config['periocular_resolution']), frame_channels=config['periocular_channels'], overlap=config['overlap'])\n",
    "            inversed_left_frames, left_duration = load_frames(left_recording_path, config['window_time'], elicitation_time_in_seconds, 120, config['periocular_sample_rate'], preprocess='flip_horizontal', resize=pair(config['periocular_resolution']), frame_channels=config['periocular_channels'], overlap=config['overlap'])\n",
    "\n",
    "            # # Process the scene recording\n",
    "            # scene_recording_path = os.path.join(config['raw_data_dir'], subject, session, 'scene', 'world.mp4')\n",
    "\n",
    "            # inversed_scene_frames, scene_duration = load_frames(scene_recording_path, config['window_time'], elicitation_time_in_seconds, 30, config['scene_sample_rate'], preprocess='none', resize=pair(config['scene_resolution']), frame_channels=config['scene_channels'], overlap=config['overlap'])\n",
    "\n",
    "            # Process the gaze and pupil recording\n",
    "            gaze_path = os.path.join(config['raw_data_dir'], subject, session, 'gaze_pupil', 'gaze.csv')\n",
    "            pupil_path = os.path.join(config['raw_data_dir'], subject, session, 'gaze_pupil', 'pupil.csv')\n",
    "\n",
    "            gaze, pupil = preprocess_gaze_pupil_data(gaze_path, pupil_path, save_path=None)\n",
    "\n",
    "            inversed_gaze_pupil = load_gaze_and_diameter(gaze, pupil, config['window_time'], config['gaze_pupil_sample_rate'], min(right_duration, left_duration), config['overlap'])\n",
    "\n",
    "            # Alginment\n",
    "            min_length = min(len(inversed_right_frames), len(inversed_left_frames), len(inversed_gaze_pupil))\n",
    "            inversed_right_frames = inversed_right_frames[:min_length]\n",
    "            inversed_left_frames = inversed_left_frames[:min_length]\n",
    "            inversed_gaze_pupil = inversed_gaze_pupil[:min_length]\n",
    "\n",
    "            # Flip to inverse to the right order\n",
    "            right_frames = np.flip(inversed_right_frames, axis=0)\n",
    "            right_frames /= 255.0  # Normalize the pixel values to the range [0, 1]\n",
    "            left_frames = np.flip(inversed_left_frames, axis=0)\n",
    "            left_frames /= 255.0  # Normalize the pixel values to the range [0, 1]\n",
    "            gaze_pupil = np.flip(inversed_gaze_pupil, axis=0)\n",
    "\n",
    "            label_dtype = np.dtype([\n",
    "                ('subject', 'i8'),\n",
    "                ('label', 'i8'),\n",
    "                ('session_label', 'S1')\n",
    "            ])\n",
    "\n",
    "            label = np.array([(subject_number, session_number, session_type)] * min_length, dtype=label_dtype)\n",
    "\n",
    "            with h5py.File(subject_h5_file, 'a') as h5f:\n",
    "                # Use chunking and compression for datasets\n",
    "                chunk_size = (1,) + right_frames.shape[1:]  # Chunk size of 1 batch\n",
    "\n",
    "                if 'labels' in h5f:\n",
    "                    h5f['labels'].resize((h5f['labels'].shape[0] + min_length,))\n",
    "                    h5f['labels'][-min_length:] = label\n",
    "                else:\n",
    "                    h5f.create_dataset('labels', data=label, maxshape=(None,), dtype=label_dtype,\n",
    "                                    chunks=True, compression=\"gzip\", compression_opts=4)\n",
    "\n",
    "                if 'gaze_pupil' in h5f:\n",
    "                    h5f['gaze_pupil'].resize((h5f['gaze_pupil'].shape[0] + min_length,) + gaze_pupil.shape[1:])\n",
    "                    h5f['gaze_pupil'][-min_length:] = gaze_pupil\n",
    "                else:\n",
    "                    h5f.create_dataset('gaze_pupil', data=gaze_pupil, maxshape=(None,) + gaze_pupil.shape[1:],\n",
    "                                    dtype=np.float32, chunks=True, compression=\"gzip\", compression_opts=4)\n",
    "\n",
    "                if 'eye0' in h5f:\n",
    "                    h5f['eye0'].resize((h5f['eye0'].shape[0] + min_length,) + right_frames.shape[1:])\n",
    "                    h5f['eye0'][-min_length:] = right_frames\n",
    "                else:\n",
    "                    h5f.create_dataset('eye0', data=right_frames, maxshape=(None,) + right_frames.shape[1:],\n",
    "                                    dtype=np.float32, chunks=chunk_size, compression=\"gzip\", compression_opts=4)\n",
    "\n",
    "                if 'eye1' in h5f:\n",
    "                    h5f['eye1'].resize((h5f['eye1'].shape[0] + min_length,) + left_frames.shape[1:])\n",
    "                    h5f['eye1'][-min_length:] = left_frames\n",
    "                else:\n",
    "                    h5f.create_dataset('eye1', data=left_frames, maxshape=(None,) + left_frames.shape[1:],\n",
    "                                    dtype=np.float32, chunks=chunk_size, compression=\"gzip\", compression_opts=4)\n",
    "\n",
    "            # Clean up\n",
    "            del right_frames, left_frames, gaze_pupil, label\n",
    "            gc.collect()\n",
    "\n",
    "            max_index_counter += min_length\n",
    "\n",
    "            session_label = f\"{session}_amount\"\n",
    "            if subject not in all_subjects_index_info:\n",
    "                all_subjects_index_info[subject] = {}\n",
    "\n",
    "            all_subjects_index_info[subject][session_label] = max_index_counter - session_amount_counter\n",
    "            session_amount_counter = max_index_counter\n",
    "\n",
    "    all_subjects_index_info[subject][\"min_index\"] = min_index_counter\n",
    "\n",
    "    all_subjects_index_info[subject][\"max_index\"] = max_index_counter - 1\n",
    "    \n",
    "    # Update the index_counter for the next subject\n",
    "    min_index_counter = max_index_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all subjects have been processed, write the aggregated index information to a JSON file\n",
    "index_info_file = os.path.join(destination_dir, 'index_info.json')\n",
    "with open(index_info_file, 'w') as f:\n",
    "    json.dump(all_subjects_index_info, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
