{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import sys\n",
    "import pprint\n",
    "import gc\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from modules.util import plant_seed, extract_parameters_from_filename\n",
    "from modules.load_data import get_test_val_train_indices\n",
    "from modules.dataset import MultiRepresentationDataset\n",
    "from models.load_model import load_create_model\n",
    "from modules.lr_scheduler import CosineScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from models.train import train_model, eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure reproducibility\n",
    "seed_worker, g = plant_seed(0)\n",
    "print(f\"os.environ.get('CUBLAS_WORKSPACE_CONFIG'): {os.environ.get('CUBLAS_WORKSPACE_CONFIG')}\") # Default is None\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "print(f\"os.environ.get('CUBLAS_WORKSPACE_CONFIG'): {os.environ.get('CUBLAS_WORKSPACE_CONFIG')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the label map and model config\n",
    "with open('models/label_map.yaml', 'r') as file:\n",
    "    label_map = yaml.safe_load(file)\n",
    "\n",
    "with open('models/model_config.json', 'r') as file:\n",
    "    model_config = json.load(file)\n",
    "\n",
    "window_time, periocular_rate, frame_size, frame_channel, gaze_pupil_rate, overlap = extract_parameters_from_filename(model_config['data_type_path'])\n",
    "model_config['window_time'] = window_time\n",
    "model_config['periocular_rate'] = periocular_rate\n",
    "model_config['frame_size'] = frame_size\n",
    "model_config['frame_channel'] = frame_channel\n",
    "model_config['gaze_pupil_rate'] = gaze_pupil_rate\n",
    "model_config['overlap'] = overlap\n",
    "\n",
    "# Check if the dataset dir exists\n",
    "dataset_dir = os.path.join(model_config['data_path'], model_config['data_type_path'])\n",
    "if not os.path.exists(dataset_dir):\n",
    "    raise FileNotFoundError(f\"The dataset directory {dataset_dir} does not exist.\")\n",
    "\n",
    "# Check if the amount of files are enough for Z-fold cross validation\n",
    "h5_files = sorted([f for f in os.listdir(dataset_dir) if f.endswith('.h5')])\n",
    "subjects = [f.replace('.h5', '') for f in h5_files]\n",
    "if len(subjects) < 5 or len(subjects) % model_config['cross_validation_fold'] != 0:\n",
    "    sys.exit(f\"The amount of subjects ({len(subjects)}) is not enough for {model_config['cross_validation_fold']}-fold cross validation.\")\n",
    "else:\n",
    "    subjects_per_fold = len(subjects) // model_config['cross_validation_fold']\n",
    "    subjects_folds = [subjects[i * subjects_per_fold:(i + 1) * subjects_per_fold] for i in range(model_config['cross_validation_fold'])]\n",
    "    pprint.pprint(subjects_folds)\n",
    "\n",
    "# Check if pretrain model path exists\n",
    "if model_config['model_path'] is not None:\n",
    "    sys.exit(f\"model_path should be None when training a new model.\")\n",
    "\n",
    "pprint.pprint(model_config)\n",
    "pprint.pprint(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "\n",
    "for fold_idx, test_subjects in enumerate(subjects_folds):\n",
    "    #==============================================================================\n",
    "    train_subjects = [subject for subject in subjects if subject not in test_subjects]\n",
    "\n",
    "    print(f\"Training fold {fold_idx + 1} with test subjects: {test_subjects}\")\n",
    "    print(f\"Training fold {fold_idx + 1} with train subjects: {train_subjects}\")\n",
    "    \n",
    "    test_indices, val_indices, train_indices, index_info = get_test_val_train_indices(test_subjects, train_subjects, dataset_dir, model_config['training_proportion'])\n",
    "\n",
    "    train_dataset = MultiRepresentationDataset(dataset_dir, train_indices, index_info)\n",
    "    val_dataset = MultiRepresentationDataset(dataset_dir, val_indices, index_info)\n",
    "    test_dataset = MultiRepresentationDataset(dataset_dir, test_indices, index_info)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=model_config['batch_size'], shuffle=True, num_workers=6, worker_init_fn=seed_worker, generator=g, pin_memory=True, prefetch_factor=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=model_config['batch_size'], shuffle=False, num_workers=6, worker_init_fn=seed_worker, generator=g, pin_memory=True, prefetch_factor=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=model_config['batch_size'], shuffle=False, num_workers=6, worker_init_fn=seed_worker, generator=g, pin_memory=True, prefetch_factor=2)\n",
    "\n",
    "    data_loaders = (train_loader, val_loader, test_loader)\n",
    "\n",
    "    #==============================================================================\n",
    "    model, vivit_params, ts_transformer_params, train_params, device = load_create_model(model_config, fold_idx, num_classes=len(label_map))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none', label_smoothing=model_config['label_smoothing'])\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1.0, betas=(train_params['beta_1'], train_params['beta_2']))\n",
    "    scheduler = CosineScheduler(max_epochs=train_params['max_update_epochs'], base_lr=train_params['base_lr'], final_lr=train_params['final_lr'], warmup_epochs=train_params['warmup_epochs'], warmup_begin_lr=train_params['warmup_begin_lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=scheduler)\n",
    "\n",
    "    #==============================================================================\n",
    "    # Train the model\n",
    "    tensorboard_writer = train_model(model, criterion, optimizer, scheduler, data_loaders, vivit_params, ts_transformer_params, train_params, model_config, fold_idx)\n",
    "\n",
    "    # Eval for the best model\n",
    "    best_model_acc, best_model_f1 = eval_model(model, data_loaders[2], model_config, label_map, tensorboard_writer, 'best')\n",
    "\n",
    "    # Eval for the last model\n",
    "    last_model_acc, last_model_f1 = eval_model(model, data_loaders[2], model_config, label_map, tensorboard_writer, 'last')\n",
    "\n",
    "    test_acc = max(best_model_acc, last_model_acc)\n",
    "    test_f1 = max(best_model_f1, last_model_f1)\n",
    "\n",
    "    total_acc += test_acc\n",
    "    total_f1 += test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average accuracy and F1 score after the loop\n",
    "average_acc = total_acc / model_config['cross_validation_fold']\n",
    "average_f1 = total_f1 / model_config['cross_validation_fold']\n",
    "\n",
    "print(f\"Average Accuracy across all folds: {average_acc}\")\n",
    "print(f\"Average F1 Score across all folds: {average_f1}\")\n",
    "\n",
    "parent_dir = os.path.dirname(model_config['model_path'])\n",
    "\n",
    "with open(os.path.join(parent_dir, \"average_acc_and_f1.txt\"), 'w') as f:\n",
    "    f.write(f\"Average Accuracy: {average_acc}\\n\")\n",
    "    f.write(f\"Average F1 Score: {average_f1}\\n\")\n",
    "\n",
    "del seed_worker, g\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
